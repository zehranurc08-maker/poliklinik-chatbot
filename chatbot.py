import streamlit as st  
import pandas as pd  
import google.generativeai as genai  
import chromadb  
import os  

# --- SAYFA YAPILANDIRMASI ---

st.set_page_config(
    page_title="Poliklinik Ã–neri Chatbotu",  # TarayÄ±cÄ± sekmesinde gÃ¶rÃ¼necek baÅŸlÄ±k
    page_icon="ğŸ¥",                          # TarayÄ±cÄ± sekmesinde gÃ¶rÃ¼necek ikon 
    layout="centered"                        # Ä°Ã§eriÄŸin sayfanÄ±n ortasÄ±nda hizalanmasÄ±nÄ± saÄŸlar
)

# --- API ANAHTARI VE MODELLERÄ°N YAPILANDIRILMASI ---
try:
     # Streamlit'in "Secrets" Ã¶zelliÄŸini kullanarak API anahtarÄ±nÄ± gÃ¼venli bir ÅŸekilde sakladÄ±k
    # Proje klasÃ¶rÃ¼nde .streamlit/secrets.toml dosyasÄ± oluÅŸturup iÃ§ine API_KEY = "..." yazmalÄ±sÄ±nÄ±z.
    # Bu yÃ¶ntem, API anahtarÄ±nÄ±zÄ±n kod iÃ§inde gÃ¶rÃ¼nmesini ve paylaÅŸÄ±lmasÄ±nÄ± engeller.
    API_KEY = st.secrets["API_KEY"]
    
    # Google AI servisini, aldÄ±ÄŸÄ±mÄ±z API anahtarÄ± ile yapÄ±landÄ±rÄ±rÄ±z.
    genai.configure(api_key=API_KEY)
    
    # Embedding iÃ§in kullanÄ±lacak modelin adÄ±nÄ± belirliyoruz.
    
    embedding_model = 'models/text-embedding-004'
    
    # Cevap Ã¼retmek iÃ§in kullanÄ±lacak Ã¼retken YZ modelini (Gemini Flash) baÅŸlatÄ±yoruz.
    generation_model = genai.GenerativeModel('gemini-2.5-flash')

except Exception as e:
    # EÄŸer try bloÄŸunda (Ã¶rn. API anahtarÄ± bulunamazsa) bir hata oluÅŸursa:
    # Ekrana bir hata mesajÄ± basarÄ±z.
    st.error(f"âŒ HATA: API anahtarÄ± yapÄ±landÄ±rÄ±lamadÄ±. LÃ¼tfen anahtarÄ±nÄ±zÄ± kontrol edin. Detay: {e}")
    # st.stop() komutu, programÄ±n geri kalanÄ±nÄ±n Ã§alÄ±ÅŸmasÄ±nÄ± durdurur.
    st.stop()

# --- CHROMA VERÄ°TABANINA BAÄLANMA ---
try:
    # 'chroma_db' klasÃ¶rÃ¼nde bulunan kalÄ±cÄ± veritabanÄ±na baÄŸlanÄ±yoruz.
    client = chromadb.PersistentClient(path="chroma_db")
    
    # VeritabanÄ± iÃ§indeki 'poliklinikler' adlÄ± koleksiyonu Ã§ekiyoruz.
    # TÃ¼m verilerimiz bu koleksiyon iÃ§inde saklanÄ±r.
    collection = client.get_collection("poliklinikler")
    
except Exception as e:
    # EÄŸer veritabanÄ± baÄŸlantÄ±sÄ±nda (Ã¶rn. 'chroma_db' klasÃ¶rÃ¼ yoksa) bir hata olursa:
    st.error(f"âŒ HATA: ChromaDB veritabanÄ±na baÄŸlanÄ±lamadÄ±. 'chroma_db' klasÃ¶rÃ¼nÃ¼n olduÄŸundan emin olun.")
    st.info("ğŸ’¡ Ä°pucu: VeritabanÄ±nÄ± oluÅŸturmak iÃ§in bir Ã¶nceki kod versiyonunu (veritabanÄ± oluÅŸturma kodu) bir kez Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekebilir.")
    st.stop() 

# --- FONKSÄ°YONLAR ---

def en_yakin_poliklinigi_bul(soru, top_n=3):
    """KullanÄ±cÄ±nÄ±n sorusunu embedding'e Ã§evirir ve veritabanÄ±nda en benzer N sonucu arar."""
    
    # 1. KullanÄ±cÄ±nÄ±n sorusunu bir embedding'e dÃ¶nÃ¼ÅŸtÃ¼r.
    soru_embedding = genai.embed_content(
        model=embedding_model,          # Hangi embedding modelini kullanacaÄŸÄ±mÄ±z
        content=soru,                   # Hangi metni vektÃ¶re Ã§evireceÄŸimiz (kullanÄ±cÄ±nÄ±n sorusu)
        task_type="RETRIEVAL_QUERY"     # Bu embedding'in bir arama sorgusu iÃ§in olduÄŸunu belirtir (daha iyi sonuÃ§lar iÃ§in optimizasyon saÄŸlar)
    )['embedding']                      # DÃ¶nen sonucun iÃ§inden sadece 'embedding' listesini alÄ±r.
    
    # 2. ChromaDB koleksiyonu iÃ§inde bu vektÃ¶re en Ã§ok benzeyen sonuÃ§larÄ± ara.
    results = collection.query(
        query_embeddings=[soru_embedding],  # Arama yapmak iÃ§in kullanÄ±cÄ±nÄ±n soru vektÃ¶rÃ¼
        n_results=top_n                     # En benzer kaÃ§ sonucu getireceÄŸini belirtir (varsayÄ±lan 3)
    )
    
    # 3. Bulunan sonuÃ§larÄ± (dokÃ¼manlar, metadatalar, mesafeler) geri dÃ¶ndÃ¼r.
    return results

def cevap_uret(soru, bulunan_sonuclar):
    """Bulunan sonuÃ§larÄ± (context) ve kullanÄ±cÄ±nÄ±n sorusunu kullanarak Gemini ile bir cevap Ã¼retir."""
    
    # ChromaDB'den dÃ¶nen sonuÃ§larÄ± ayÄ±klar.
    # 'documents' aranan metne karÅŸÄ±lÄ±k gelen semptom metinleridir.
    documents = bulunan_sonuclar['documents'][0]
    # 'metadatas' o semptomlara baÄŸlÄ± poliklinik bilgileridir.
    metadatas = bulunan_sonuclar['metadatas'][0]
    
    # EÄŸer 'documents' listesi boÅŸsa, yani veritabanÄ±nda hiÃ§bir benzer sonuÃ§ bulunamamÄ±ÅŸsa:
    if not documents:
        # Standart bir "bulunamadÄ±" mesajÄ± dÃ¶ndÃ¼rÃ¼r.
        return "ÃœzgÃ¼nÃ¼m, belirttiÄŸiniz ÅŸikayetlerle ilgili bir poliklinik Ã¶nerisi bulamadÄ±m. LÃ¼tfen bir saÄŸlÄ±k kuruluÅŸuna danÄ±ÅŸÄ±n."

    # Bulunan sonuÃ§larÄ± (ilgili semptom ve poliklinik) modelin anlayacaÄŸÄ± bir 'context' metnine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼rÃ¼z.
    # zip(documents, metadatas) -> (semptom1, poliklinik1), (semptom2, poliklinik2)... eÅŸleÅŸtirmesi yapar.
    context = "\n".join([f"Ä°lgili Semptom: {doc}, Gitmesi Gereken Poliklinik: {meta['poliklinik']}" for doc, meta in zip(documents, metadatas)])

    # Gemini modeline gÃ¶ndereceÄŸimiz prompt hazÄ±rlÄ±yoruz.
    # Bu, modelin nasÄ±l davranacaÄŸÄ±nÄ±, hangi bilgileri kullanacaÄŸÄ±nÄ± belirten bir ÅŸablondur.
    prompt = f"""
    Sen, kullanÄ±cÄ±nÄ±n saÄŸlÄ±k sorunlarÄ±na gÃ¶re hangi polikliniÄŸe gitmesi gerektiÄŸini Ã¶neren bir yardÄ±mcÄ± asistansÄ±n.
    Sana kullanÄ±cÄ±nÄ±n sorusunu ve veritabanÄ±ndan bulduÄŸun en ilgili semptomlarÄ± vereceÄŸim.
    Bu bilgilere dayanarak, kullanÄ±cÄ±ya nazik, samimi ve anlaÅŸÄ±lÄ±r bir dille Ã¶neride bulun.
    CevabÄ±nda tÄ±bbi bir teÅŸhis koymadÄ±ÄŸÄ±nÄ±, sadece bir yÃ¶nlendirme yaptÄ±ÄŸÄ±nÄ± belirt.
    Sadece verdiÄŸim bilgi metnindeki poliklinikleri Ã¶ner.
    
    VERÄ°LEN BÄ°LGÄ° METNÄ°:
    {context}
    
    KULLANICININ SORUSU:
    "{soru}"
    
    CEVAP:
    """
    
    # HazÄ±rlanan prompt'u Gemini modeline gÃ¶ndeririz.
    response = generation_model.generate_content(prompt)
    
    # Modelden gelen cevabÄ±n sadece metin kÄ±smÄ±nÄ± geri dÃ¶ndÃ¼rÃ¼rÃ¼z.
    return response.text

# --- STREAMLIT ARAYÃœZÃœ (UygulamanÄ±n ana akÄ±ÅŸÄ±) ---


st.title("ğŸ¥ Poliklinik Ã–neri Chatbotu")
st.caption("LÃ¼tfen yaÅŸadÄ±ÄŸÄ±nÄ±z saÄŸlÄ±k sorununu veya belirtilerinizi aÅŸaÄŸÄ±daki kutucuÄŸa yazÄ±n.")

# Girilen metin 'user_input' deÄŸiÅŸkenine atanÄ±r.
user_input = st.text_input("Åikayetinizi buraya yazÄ±n...", key="user_input")

# 'if user_input:' bloÄŸu, kullanÄ±cÄ± kutucuÄŸa bir ÅŸey yazÄ±p Enter'a bastÄ±ÄŸÄ± anda Ã§alÄ±ÅŸÄ±r.
if user_input:
    # 'with st.spinner(...)' bloÄŸu, iÃ§indeki kodlar Ã§alÄ±ÅŸÄ±rken kullanÄ±cÄ±ya bir bekleme mesajÄ± gÃ¶sterir.
    with st.spinner('Sizin iÃ§in en uygun polikliniÄŸi arÄ±yorum... LÃ¼tfen bekleyin...'):
        
        # 1. AdÄ±m: KullanÄ±cÄ±nÄ±n girdiÄŸi metni (user_input) al ve veritabanÄ±nda en benzer sonuÃ§larÄ± bul.
        benzer_sonuclar = en_yakin_poliklinigi_bul(user_input)
        
        # 2. AdÄ±m: Bulunan benzer sonuÃ§larÄ± (benzer_sonuclar) ve kullanÄ±cÄ±nÄ±n sorusunu (user_input)
        #           'cevap_uret' fonksiyonuna gÃ¶ndererek modelden bir cevap oluÅŸturmasÄ±nÄ± iste.
        chatbot_cevabi = cevap_uret(user_input, benzer_sonuclar)
        
        # 3. AdÄ±m: Ãœretilen cevabÄ± kullanÄ±cÄ±ya gÃ¶ster.
        st.markdown("---") 
        st.write("ğŸ¤– Chatbot'un Ã–nerisi:") 
        st.info(chatbot_cevabi)